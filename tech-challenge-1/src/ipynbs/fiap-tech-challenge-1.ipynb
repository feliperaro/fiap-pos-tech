{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzRATyG7FK1q"
      },
      "source": [
        "# **__O Problema__**\n",
        "\n",
        "Você é um profissional encarregado de desenvolver um modelo preditivo de regressão para prever o valor dos custos médicos individuais cobrados pelo seguro de saúde.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K8S5LKSFpbx"
      },
      "source": [
        "A base de dados para este desafio será a seguinte:\n",
        "\n",
        "https://github.com/feliperaro/fiap-pos-tech/blob/main/tech-challenge-1/resources/datasets/insurance.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5MMfOy0GYNK"
      },
      "source": [
        "\n",
        "Neste notebook, vamos explorar e preparar os dados, treinar diferentes modelos de machine learning e, finalmente, avaliar qual modelo oferece a melhor precisão para prever o valor dos custos médicos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYqOZ2xrEIEU"
      },
      "source": [
        "# Importação de Bibliotecas\n",
        "Para iniciar, instalamos e importamos as bibliotecas necessárias para manipulação de dados, visualização e construção dos modelos de machine learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3UB8Goa8GxO"
      },
      "outputs": [],
      "source": [
        "# !conda install scikit-learn matplotlib numpy pandas seaborn -y\n",
        "# !pip install scikit-learn matplotlib numpy pandas seaborn -y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXkUV-XSIRnI"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import requests\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Sox7RH7Glxz"
      },
      "source": [
        "# Carregamento de Dados\n",
        "Download e leitura do dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_bHlTnEDiFk"
      },
      "outputs": [],
      "source": [
        "def download_dataset():\n",
        "    url = \"https://raw.githubusercontent.com/feliperaro/fiap-pos-tech/refs/heads/main/tech-challenge-1/resources/datasets/insurance.csv\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to download file. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "    with open(\"dataset.csv\", \"wb\") as file:\n",
        "        file.write(response.content)\n",
        "\n",
        "download_dataset()\n",
        "dataset = pd.read_csv(\"dataset.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgwrdrHx8GxR"
      },
      "source": [
        "# Análise Exploratória dos Dados (EDA)\n",
        "Nesta seção, exploramos as variáveis do dataset e analisamos suas distribuições.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-GudURM8GxR"
      },
      "outputs": [],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwXkcLnU8GxS"
      },
      "outputs": [],
      "source": [
        "dataset.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtp_8Xhj8GxT"
      },
      "outputs": [],
      "source": [
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xY4mZJMrAh3l"
      },
      "outputs": [],
      "source": [
        "dataset.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xsBNn_y8GxU"
      },
      "outputs": [],
      "source": [
        "dataset.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAN86DDD8GxU"
      },
      "outputs": [],
      "source": [
        "dataset.duplicated().value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TE-Zb7dk8GxV"
      },
      "outputs": [],
      "source": [
        "dataset.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOpNZW9GSguI"
      },
      "outputs": [],
      "source": [
        "string_columns = [\"sex\", \"smoker\", \"region\"]\n",
        "for col in string_columns:\n",
        "    print(f\"{col}: {dataset[col].unique()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCwsZoocApVh"
      },
      "outputs": [],
      "source": [
        "data_to_translate = {\n",
        "    \"columns\": {\n",
        "        \"age\": \"idade\",\n",
        "        \"sex\": \"genero\",\n",
        "        \"bmi\": \"imc\",\n",
        "        \"children\": \"filhos\",\n",
        "        \"smoker\": \"fumante\",\n",
        "        \"region\": \"regiao\",\n",
        "        \"charges\": \"custos\"\n",
        "    },\n",
        "    \"values\": {\n",
        "        \"male\": \"masculino\",\n",
        "        \"female\": \"feminino\",\n",
        "        \"yes\": \"sim\",\n",
        "        \"no\": \"nao\",\n",
        "        \"northeast\": \"nordeste\",\n",
        "        \"northwest\": \"noroeste\",\n",
        "        \"southeast\": \"sudeste\",\n",
        "        \"southwest\": \"sudoeste\"\n",
        "    }\n",
        "}\n",
        "\n",
        "for key, value in data_to_translate.items():\n",
        "    if key == \"columns\":\n",
        "        dataset = dataset.rename(columns=value)\n",
        "    elif key == \"values\":\n",
        "        dataset = dataset.replace(value)\n",
        "...\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXodsURg8GxX"
      },
      "outputs": [],
      "source": [
        "dataset.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOqn7VJqD50n"
      },
      "outputs": [],
      "source": [
        "dataset.hist(bins=50, figsize=(10, 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dQ9RrPE8GxY"
      },
      "outputs": [],
      "source": [
        "dataset['grupo_idade'] = pd.cut(\n",
        "    dataset['idade'],\n",
        "    bins=[20, 35, 50, 65],  # Intervalos para as faixas\n",
        "    labels=['Jovem', 'Meia-Idade', 'Sênior'],  # Rótulos para cada faixa\n",
        "    right=False  # Inclui o limite inferior em cada faixa\n",
        ")\n",
        "\n",
        "age_cost_mean = dataset.groupby('grupo_idade', observed=True)['custos'].mean()\n",
        "\n",
        "print(age_cost_mean)\n",
        "age_cost_mean.plot(kind='bar', figsize=(10, 6), color='skyblue')\n",
        "\n",
        "plt.title(\"Média do Custo por Faixa Etária\")\n",
        "plt.xlabel(\"Faixa Etária\")\n",
        "plt.ylabel(\"Média do Custo\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5cOjcwj8GxY"
      },
      "outputs": [],
      "source": [
        "colunas = [\"genero\", \"fumante\", \"regiao\", \"idade\", \"imc\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQcq9nIInW_I"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "for coluna in colunas:\n",
        "    sns.countplot(x=coluna, data=dataset, legend=False)\n",
        "    plt.title('Distribuição')\n",
        "\n",
        "    plt.xlabel(coluna)\n",
        "    plt.ylabel(\"Quantidade\")\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WG5RLvM8GxZ"
      },
      "outputs": [],
      "source": [
        "for column in colunas:\n",
        "    sns.boxplot(x=column, y='custos', data=dataset)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLu0iQlG8GxZ"
      },
      "source": [
        "# Preparação dos Dados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uF0wB4Y98GxZ"
      },
      "outputs": [],
      "source": [
        "dataset = pd.get_dummies(dataset, drop_first=True)\n",
        "dataset.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ec5KNWPw8GxZ"
      },
      "outputs": [],
      "source": [
        "X = dataset.drop('custos', axis=1)\n",
        "y = dataset['custos']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "predicts = model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO2D5JYx8Gxa"
      },
      "source": [
        "# Detecção e Remoção de Outliers\n",
        "\n",
        "Outliers são valores que estão fora do padrão esperado e podem distorcer a análise e o desempenho dos modelos de machine learning. Nesta etapa, vamos identificar e remover esses valores para obter um conjunto de dados mais limpo e representativo usando o IQR (Intervalo Interquartil) para melhorar a qualidade dos dados.\n",
        "\n",
        "1. **Calcular o IQR (Intervalo Interquartil)**:\n",
        "   - Calculamos o primeiro quartil (Q1 == 25%) e o terceiro quartil (Q3 == 75%) de cada variável numérica. A diferença entre eles (Q3 - Q1) é o IQR, que representa a dispersão central dos dados.\n",
        "\n",
        "2. **Definir Limites para Outliers**:\n",
        "   - Usamos a regra comum para detectar outliers, considerando como \"fora do padrão\" os valores que estão abaixo de `25%` ou acima de `75%`.\n",
        "   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlYgBdvp8Gxa"
      },
      "source": [
        "**remove_outliers()**:\n",
        "   - Cria uma máscara (filtro) para manter apenas as linhas com valores dentro dos limites normais, removendo linhas que possuem outliers em alguma variável numérica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vM8oZgxj8Gxa"
      },
      "outputs": [],
      "source": [
        "def remove_outliers(df, features):\n",
        "    mask = True\n",
        "    for feature in features:\n",
        "        mask &= (\n",
        "            df[feature] >= (Q1[feature] - 1.5 * IQR[feature])) & (df[feature] <= (Q3[feature] + 1.5 * IQR[feature])\n",
        "        )\n",
        "    return df[mask]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I15FZBSz8Gxa"
      },
      "outputs": [],
      "source": [
        "features_numericas = dataset.select_dtypes(include=['float64', 'int64']).columns\n",
        "print(\"features_numericas:\", features_numericas)\n",
        "\n",
        "Q1 = dataset[features_numericas].quantile(0.25)\n",
        "Q3 = dataset[features_numericas].quantile(0.75)\n",
        "\n",
        "IQR = Q3 - Q1\n",
        "print(\"Tamanho do DataFrame Original:\", dataset.shape)\n",
        "\n",
        "dataset_limpo = remove_outliers(dataset, features_numericas)\n",
        "print(\"dataset_limpo.shape:\", dataset_limpo.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9z0BFKw8Gxa"
      },
      "outputs": [],
      "source": [
        "X = dataset_limpo.drop('custos', axis=1)\n",
        "y = dataset_limpo['custos']\n",
        "\n",
        "X_train_cleaned, X_test_cleaned, y_train_cleaned, y_test_cleaned = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_cleaned, y_train_cleaned)\n",
        "predicts_cleaned = model.predict(X_test_cleaned)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnFL-nqY8Gxa"
      },
      "outputs": [],
      "source": [
        "mae_original = mean_absolute_error(y_test, predicts)\n",
        "mse_original = mean_squared_error(y_test, predicts)\n",
        "\n",
        "mae_cleaned = mean_absolute_error(y_test_cleaned, predicts_cleaned)\n",
        "mse_cleaned = mean_squared_error(y_test_cleaned, predicts_cleaned)\n",
        "\n",
        "print(f\"Desempenho no dataset original - MAE: {mae_original}, MSE: {mse_original}\")\n",
        "print(f\"Desempenho no dataset limpo - MAE: {mae_cleaned}, MSE: {mse_cleaned}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxSS9ekQ8Gxb"
      },
      "outputs": [],
      "source": [
        "dataset = dataset_limpo\n",
        "\n",
        "X = dataset.drop('custos', axis=1)\n",
        "y = dataset['custos']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
        "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for model_name, model in models.items():\n",
        "    cv_mse_scores = cross_val_score(\n",
        "        model,\n",
        "        X_train,\n",
        "        y_train,\n",
        "        cv=5,\n",
        "        scoring='neg_mean_squared_error'\n",
        "    )\n",
        "\n",
        "    cv_mae_scores = cross_val_score(\n",
        "        model,\n",
        "        X_train,\n",
        "        y_train,\n",
        "        cv=5,\n",
        "        scoring='neg_mean_absolute_error'\n",
        "    )\n",
        "\n",
        "    results[model_name] = {\n",
        "        \"Mean MSE (CV)\": -cv_mse_scores.mean(),\n",
        "        \"MSE Scores (CV)\": -cv_mse_scores,\n",
        "        \"Mean MAE (CV)\": -cv_mae_scores.mean(),\n",
        "        \"MAE Scores (CV)\": -cv_mae_scores\n",
        "    }\n",
        "    model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1zoIfjk8Gxb"
      },
      "outputs": [],
      "source": [
        "for model_name, metrics in results.items():\n",
        "    mse_scores = metrics['MSE Scores (CV)']\n",
        "    mae_scores = metrics['MAE Scores (CV)']\n",
        "\n",
        "    print(f\"{model_name}:\")\n",
        "    print(f\"Mean MSE (CV): {metrics['Mean MSE (CV)']:.2f}\")\n",
        "    print(f\"MSE Scores (CV): {mse_scores}\")\n",
        "    print(f\"Mean MAE (CV): {metrics['Mean MAE (CV)']:.2f}\")\n",
        "    print(f\"MAE Scores (CV): {mae_scores}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itBelzg78Gxb"
      },
      "source": [
        "## Comparação de Modelos\n",
        "\n",
        "Comparação dos três modelos – **Regressão Linear**, **Árvore de Decisão** e **Random Forest** – usando validação cruzada para avaliar o desempenho de cada um com as métricas **Mean Squared Error (MSE)** e **Mean Absolute Error (MAE)**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSM3Jl558Gxc"
      },
      "outputs": [],
      "source": [
        "evaluation_results = {}\n",
        "for model_name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    evaluation_results[model_name] = {\n",
        "        \"Mean Squared Error\": mse,\n",
        "        \"R² Score\": r2\n",
        "    }\n",
        "\n",
        "for model_name, metrics in evaluation_results.items():\n",
        "    print(f\"{model_name}: MSE = {metrics['Mean Squared Error']:.2f}, R² = {metrics['R² Score']:.2f}\")\n",
        "\n",
        "model_names = list(evaluation_results.keys())\n",
        "mse_values = [metrics['Mean Squared Error'] for metrics in evaluation_results.values()]\n",
        "r2_values = [metrics['R² Score'] for metrics in evaluation_results.values()]\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.bar(model_names, mse_values, color='skyblue')\n",
        "plt.title('Mean Squared Error')\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.bar(model_names, r2_values, color='salmon')\n",
        "plt.title('R² Score')\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('R² Score')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusão\n",
        "\n",
        "O **Random Forest** foi o modelo que apresentou o melhor desempenho geral, com o menor **Mean MSE** e **Mean MAE** entre os três modelos avaliados. Isso significa que o Random Forest:\n",
        "- Possui menor variabilidade nas previsões, refletido pelo MSE mais baixo.\n",
        "- Faz previsões mais próximas dos valores reais, indicado pelo menor MAE.\n",
        "\n",
        "Portanto, com base nos resultados, o **Random Forest** é a melhor escolha para prever os custos médicos, oferecendo uma combinação equilibrada entre precisão e robustez para lidar com as variáveis deste dataset."
      ],
      "metadata": {
        "id": "pqgnNl2I9V0k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FwDcQRt8Gxc"
      },
      "outputs": [],
      "source": [
        "best_model = RandomForestRegressor(random_state=42)\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Best Model MSE: {mse:.4f}, R² Score: {r2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(y_test, y_pred, color='blue', alpha=0.6)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "plt.xlabel('Valores Reais')\n",
        "plt.ylabel('Valores Preditos')\n",
        "plt.title('Valores Reais vs Preditos')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CZw9fIPN9GeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuGKFh0u8Gxh"
      },
      "source": [
        "# Próximos Passos\n",
        "\n",
        "Após a análise e comparação dos modelos, identificamos que o **Random Forest** apresentou o melhor desempenho geral na previsão dos custos médicos, tanto antes quanto depois da remoção dos outliers. A seguir, listamos algumas sugestões de próximos passos para aprimorar ainda mais o modelo e o processo de análise:\n",
        "\n",
        "### 1. Testar Outros Modelos de Machine Learning\n",
        "   - Experimentar modelos mais complexos, como **Gradient Boosting** ou **XGBoost**, que frequentemente têm um bom desempenho em problemas de regressão e podem capturar padrões mais sutis nos dados.\n",
        "   - Avaliar o desempenho desses modelos comparado ao Random Forest para garantir que temos a melhor escolha.\n",
        "\n",
        "### 2. Feature Engineering\n",
        "   - Explorar novas combinações de variáveis (features), como **interações entre variáveis** ou **transformações logarítmicas**, que possam capturar melhor a relação entre variáveis e custos.\n",
        "   - A criação de variáveis derivadas pode ajudar o modelo a entender padrões ocultos nos dados, especialmente se houver relações não lineares.\n",
        "\n",
        "### 3. Implementação em Produção\n",
        "   - Desenvolver um **pipeline de produção** para implementar o modelo, permitindo que ele faça previsões em tempo real.\n",
        "   - Esse pipeline pode incluir a preparação dos dados (limpeza e transformação), aplicação do modelo treinado e armazenamento das previsões.\n",
        "   - Monitorar o desempenho do modelo ao longo do tempo para ajustar caso haja mudanças nos dados ou nas condições do problema.\n",
        "\n",
        "### 4. Monitoramento e Atualização do Modelo\n",
        "   - Estabelecer um sistema de **monitoramento contínuo** para acompanhar o desempenho do modelo ao longo do tempo e detectar possíveis drifts de dados, que podem ocorrer se o perfil dos dados mudar.\n",
        "   - Realizar re-treinamento periódico para atualizar o modelo com novos dados, garantindo que ele permaneça preciso e relevante.\n",
        "\n",
        "Esses próximos passos ajudarão a garantir que o modelo seja robusto, confiável e eficiente em um cenário de produção, além de permitir um monitoramento e uma evolução contínua conforme o problema e os dados mudam.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}